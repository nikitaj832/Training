{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0473e323-4011-4ca9-9b5f-09025a188720",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Create a simple streaming query with trigger intervals.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c93aa6dc-0ee9-4e2c-af21-4de62f59fefb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StringType, IntegerType\n",
    "\n",
    "schema = StructType() \\\n",
    "    .add(\"name\", StringType()) \\\n",
    "    .add(\"age\", IntegerType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4be3fef5-161b-4bd9-8235-dbb189d415e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[2]: True"
     ]
    }
   ],
   "source": [
    "dbutils.fs.mkdirs(\"/tmp/stream_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "255bd4f7-450d-4ec2-8748-df3984d32dcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Start Streaming Query with Trigger Interval\n",
    "streaming_df = spark.readStream \\\n",
    "    .schema(schema) \\\n",
    "    .json(\"/tmp/stream_data\")  # Directory to watch for new files\n",
    "\n",
    "query = streaming_df.writeStream \\\n",
    "    .format(\"console\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .trigger(processingTime=\"10 seconds\") \\\n",
    "    .start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3aef8a32-7fdc-4cb1-ad1b-82fbab2e8029",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[4]: {'message': 'Getting offsets from FileStreamSource[dbfs:/tmp/stream_data]',\n 'isDataAvailable': False,\n 'isTriggerActive': True}"
     ]
    }
   ],
   "source": [
    "query.status\n",
    "# or use: query.lastProgress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36173c98-6a8b-4953-b4ee-335f859ab83c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 26 bytes.\nOut[5]: True"
     ]
    }
   ],
   "source": [
    "dbutils.fs.put(\"/tmp/stream_data/data1.json\", '{\"name\":\"Alice\", \"age\":30}', True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "735897de-fb80-4230-b767-45586a6934cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Build a sample structured streaming pipeline.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac30fa1f-0379-41f4-94b5-5ab55c968c48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StringType, IntegerType\n",
    "\n",
    "schema = StructType() \\\n",
    "    .add(\"name\", StringType()) \\\n",
    "    .add(\"age\", IntegerType()) \\\n",
    "    .add(\"city\", StringType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "792c8829-dde5-41cd-a84e-c521af07b443",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[7]: True"
     ]
    }
   ],
   "source": [
    "dbutils.fs.mkdirs(\"/tmp/input_data/\")\n",
    "dbutils.fs.mkdirs(\"/tmp/output_data/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3045d3a-98a2-4c15-974c-0e7349fbc340",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "input_stream = spark.readStream \\\n",
    "    .schema(schema) \\\n",
    "    .json(\"/tmp/input_data/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7ee5f8f-72c6-40f7-ae0a-daa6a39a2bdd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filtered_stream = input_stream.filter(\"age >= 18\") \\\n",
    "    .select(\"name\", \"city\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0755eeca-3236-460d-bdfb-d357832a8c27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write to Sink (File) with Trigger\n",
    "query = filtered_stream.writeStream \\\n",
    "    .format(\"json\") \\\n",
    "    .option(\"path\", \"/tmp/output_data/\") \\\n",
    "    .option(\"checkpointLocation\", \"/tmp/checkpoint/\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .trigger(processingTime=\"5 seconds\") \\\n",
    "    .start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "176ede7e-f9e7-47a8-872f-b5748319d235",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[12]: {'message': 'Waiting for next trigger',\n 'isDataAvailable': False,\n 'isTriggerActive': False}"
     ]
    }
   ],
   "source": [
    "query.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c272491-8105-4ecd-b62d-46a35dbacd13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 49 bytes.\nWrote 47 bytes.\nOut[13]: True"
     ]
    }
   ],
   "source": [
    "dbutils.fs.put(\"/tmp/input_data/sample1.json\", '''\n",
    "{\"name\": \"Nikita\", \"age\": 23, \"city\": \"Jaipur\"}\n",
    "''', True)\n",
    "\n",
    "dbutils.fs.put(\"/tmp/input_data/sample2.json\", '''\n",
    "{\"name\": \"Aarav\", \"age\": 17, \"city\": \"Delhi\"}\n",
    "''', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6174be7-79c3-46ab-8cda-86b3cc6628b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "affee2cb-5588-4b92-a6b7-c220231d602a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Implement watermarking to manage late data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a69c22a-a894-4bbc-86ee-9eeec44172ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StringType, TimestampType\n",
    "\n",
    "schema = StructType() \\\n",
    "    .add(\"user\", StringType()) \\\n",
    "    .add(\"action\", StringType()) \\\n",
    "    .add(\"event_time\", TimestampType())  # Event time column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b95cdb70-9118-4141-b276-dd45a891e58a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[19]: True"
     ]
    }
   ],
   "source": [
    "dbutils.fs.mkdirs(\"/tmp/event_data/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "316e6df8-32be-477b-9573-f56be31dd8de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 76 bytes.\nOut[20]: True"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "event_time = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "dbutils.fs.put(\"/tmp/event_data/sample1.json\", f'''\n",
    "{{\"user\": \"Nikita\", \"action\": \"login\", \"event_time\": \"{event_time}\"}}\n",
    "''', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28a80ce2-4e32-4c2c-a4fb-43f709fc6e98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "input_stream = spark.readStream \\\n",
    "    .schema(schema) \\\n",
    "    .json(\"/tmp/event_data/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11e649a7-8be0-42ab-9933-fb43c431edc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import window\n",
    "\n",
    "aggregated_stream = input_stream \\\n",
    "    .withWatermark(\"event_time\", \"10 minutes\") \\\n",
    "    .groupBy(\n",
    "        window(\"event_time\", \"5 minutes\"),\n",
    "        \"action\"\n",
    "    ).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44215238-3c77-466b-adfb-59fd1c09d883",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Write Output to File Sink\n",
    "query = aggregated_stream.writeStream \\\n",
    "    .format(\"json\") \\\n",
    "    .option(\"path\", \"/tmp/aggregated_output/\") \\\n",
    "    .option(\"checkpointLocation\", \"/tmp/checkpoint_watermarking/\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .trigger(processingTime=\"10 seconds\") \\\n",
    "    .start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf537989-d475-45a7-adfa-6aee66a9d341",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 75 bytes.\nWrote 73 bytes.\nOut[28]: True"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# On-time data (processed)\n",
    "event_time_ontime = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')\n",
    "dbutils.fs.put(\"/tmp/event_data/on_time.json\", f'''\n",
    "{{\"user\": \"Alice\", \"action\": \"click\", \"event_time\": \"{event_time_ontime}\"}}\n",
    "''', True)\n",
    "\n",
    "# Late data (older than watermark threshold = will be dropped)\n",
    "event_time_late = (datetime.now() - timedelta(minutes=15)).strftime('%Y-%m-%dT%H:%M:%S')\n",
    "dbutils.fs.put(\"/tmp/event_data/late.json\", f'''\n",
    "{{\"user\": \"Bob\", \"action\": \"click\", \"event_time\": \"{event_time_late}\"}}\n",
    "''', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2cd96e7d-e658-4587-8099-2e36eba07d0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Structured Streaming",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}