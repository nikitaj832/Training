{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44c6dc17-27d5-413b-bdae-cbe53c81c23a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Write a UDF to convert string values to uppercase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6576f8a4-be81-400a-94e5-96c70d6734d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import St\n",
    "ringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d373da2-9dcb-41ad-bdd5-58394dd9e7a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the UDF Function\n",
    "def to_uppercase(s):\n",
    "    if s:\n",
    "        return s.upper()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7b01c30-4671-4bda-a0d3-54a583e2f1f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Register the UDF\n",
    "uppercase_udf = udf(to_uppercase, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ff228e3-6c83-47b7-b1d7-833a2b96c1dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n|  name|\n+------+\n|nikita|\n|  jain|\n|  null|\n+------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [(\"nikita\",), (\"jain\",), (None,)]\n",
    "df = spark.createDataFrame(data, [\"name\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc328377-1f6d-4013-9dfb-c06053071740",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n|  name|name_upper|\n+------+----------+\n|nikita|    NIKITA|\n|  jain|      JAIN|\n|  null|      null|\n+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Apply the UDF\n",
    "df_upper = df.withColumn(\"name_upper\", uppercase_udf(df[\"name\"]))\n",
    "df_upper.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1e41bb9-991b-430b-9342-e92898d8f661",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Create a UDF to check if a value in a column is prime or not**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6af86519-fd6d-429f-9b03-b03460f86ba0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def is_prime(n):\n",
    "    if n is None or n < 2:\n",
    "        return \"Not Prime\"\n",
    "    for i in range(2, int(n**0.5) + 1):\n",
    "        if n % i == 0:\n",
    "            return \"Not Prime\"\n",
    "    return \"Prime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0469966-d2e9-4a88-a7ac-781fdc6e3d79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Register the Function as a UDF\n",
    "prime_udf = udf(is_prime, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3cbe089-de25-415b-aab9-635152d6d41c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n|number|\n+------+\n|     2|\n|     3|\n|     4|\n|     5|\n|    10|\n|    13|\n|    16|\n|  null|\n+------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [(2,), (3,), (4,), (5,), (10,), (13,), (16,), (None,)]\n",
    "df = spark.createDataFrame(data, [\"number\"])\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8a4f669-2f43-4e2b-84ae-0bbb2b086c2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n|number|prime_status|\n+------+------------+\n|     2|       Prime|\n|     3|       Prime|\n|     4|   Not Prime|\n|     5|       Prime|\n|    10|   Not Prime|\n|    13|       Prime|\n|    16|   Not Prime|\n|  null|   Not Prime|\n+------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "df_prime = df.withColumn(\"prime_status\", prime_udf(df[\"number\"]))\n",
    "df_prime.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "700b8348-3efd-4edf-b7c5-c7d77e6e727c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "UDFs & Future Updates",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}