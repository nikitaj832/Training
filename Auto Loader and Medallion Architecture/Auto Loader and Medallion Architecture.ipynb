{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9562cc69-355f-49c0-b54d-1a2aa8c933ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Use Auto Loader to automate file loading.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bfa106f-4844-4300-9e00-e9e0846b48f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[5]: [FileInfo(path='dbfs:/FileStore/tables/employees-1.csv', name='employees-1.csv', size=3778, modificationTime=1749218486000),\n FileInfo(path='dbfs:/FileStore/tables/employees-2.csv', name='employees-2.csv', size=3778, modificationTime=1749218504000),\n FileInfo(path='dbfs:/FileStore/tables/employees-3.csv', name='employees-3.csv', size=3778, modificationTime=1749229958000),\n FileInfo(path='dbfs:/FileStore/tables/employees.csv', name='employees.csv', size=3778, modificationTime=1749218423000)]"
     ]
    }
   ],
   "source": [
    "\n",
    "dbutils.fs.ls('/FileStore/tables')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c97e7c5-2c13-45d4-90b4-47c44ac2a151",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    " # Code for Auto Loader in Databricks\n",
    "from pyspark.sql.types import StructType, StringType, IntegerType\n",
    "\n",
    "# Step 1: Define the schema of your employee data\n",
    "schema = StructType() \\\n",
    "    .add(\"id\", IntegerType()) \\\n",
    "    .add(\"name\", StringType()) \\\n",
    "    .add(\"age\", IntegerType())\n",
    "\n",
    "# Step 2: Set up Auto Loader to read new files\n",
    "df = (spark.readStream\n",
    "      .format(\"cloudFiles\")\n",
    "      .option(\"cloudFiles.format\", \"csv\")  # Input format\n",
    "      .schema(schema)\n",
    "      .load(\"/FileStore/tables/\"))  # Your uploaded path\n",
    "\n",
    "# Step 3: Stream output to Delta table folder\n",
    "query = (df.writeStream\n",
    "         .format(\"delta\")\n",
    "         .outputMode(\"append\")\n",
    "         .option(\"checkpointLocation\", \"/FileStore/employee_checkpoint/\")  # Required for streaming\n",
    "         .start(\"/FileStore/employee_output/\"))  # Output path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd59708c-a8ec-4162-91d9-3059cc484e44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----+\n|  id|      name| age|\n+----+----------+----+\n|null|FIRST_NAME|null|\n| 198|    Donald|null|\n| 199|   Douglas|null|\n| 200|  Jennifer|null|\n| 201|   Michael|null|\n| 202|       Pat|null|\n| 203|     Susan|null|\n| 204|   Hermann|null|\n| 205|   Shelley|null|\n| 206|   William|null|\n| 100|    Steven|null|\n| 101|     Neena|null|\n| 102|       Lex|null|\n| 103| Alexander|null|\n| 104|     Bruce|null|\n| 105|     David|null|\n| 106|     Valli|null|\n| 107|     Diana|null|\n| 108|     Nancy|null|\n| 109|    Daniel|null|\n+----+----------+----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark.read.format(\"delta\").load(\"/FileStore/employee_output/\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b3a8458-9f22-4efa-8c4c-dc6fd2702371",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[8]: {'message': 'Waiting for data to arrive',\n 'isDataAvailable': False,\n 'isTriggerActive': False}"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de7d57b8-4800-4357-bac0-94e065a952cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Set up a simple Medallion pipeline to move data from raw (bronze) to cleansed (silver) to curated (gold).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0539a2a-1db7-4e8f-909a-a8e5f1d225d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[38]: [FileInfo(path='dbfs:/FileStore/tables/employees-1.csv', name='employees-1.csv', size=3778, modificationTime=1749218486000),\n FileInfo(path='dbfs:/FileStore/tables/employees-2.csv', name='employees-2.csv', size=3778, modificationTime=1749218504000),\n FileInfo(path='dbfs:/FileStore/tables/employees-3.csv', name='employees-3.csv', size=3778, modificationTime=1749229958000),\n FileInfo(path='dbfs:/FileStore/tables/employees-fresh.csv', name='employees-fresh.csv', size=42, modificationTime=1749822020000),\n FileInfo(path='dbfs:/FileStore/tables/employees.csv', name='employees.csv', size=3778, modificationTime=1749218423000)]"
     ]
    }
   ],
   "source": [
    "dbutils.fs.ls('/FileStore/tables')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09e40eeb-95e1-4108-b455-0642a832ff0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Bronze Layer – Load Raw Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe48c4e5-9b87-47a4-b4ac-2d31428e0156",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# STEP 1: Define Schema\n",
    "from pyspark.sql.types import StructType, StringType, IntegerType\n",
    "\n",
    "schema = StructType() \\\n",
    "    .add(\"id\", IntegerType()) \\\n",
    "    .add(\"name\", StringType()) \\\n",
    "    .add(\"age\", IntegerType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c65388e-ea8e-4a79-9a4b-ff55142c0bfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# STEP 2: Bronze - Ingest raw CSVs with Auto Loader\n",
    "bronze_df = (spark.readStream\n",
    "    .format(\"cloudFiles\")\n",
    "    .option(\"cloudFiles.format\", \"csv\")\n",
    "    .schema(schema)\n",
    "    .load(\"/FileStore/tables/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1cf346c-f353-4f63-a7de-342e8f89ee47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze_query = (bronze_df.writeStream\n",
    "    .format(\"delta\")\n",
    "    .outputMode(\"append\")\n",
    "    .option(\"checkpointLocation\", \"/FileStore/bronze_checkpoint_v1/\")\n",
    "    .start(\"/FileStore/bronze_table_v1/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6af3aaa5-d738-4299-91f9-e2d2ed9af2d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Silver Layer – Clean or Filter Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc5bfa3f-87ed-4ed3-8731-1d542482b4e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#STEP 3: Silver - Clean and filter data\n",
    "silver_df = spark.readStream.format(\"delta\").load(\"/FileStore/bronze_table_v1/\")\n",
    "\n",
    "cleansed_df = silver_df.filter(\"age IS NOT NULL AND age >= 18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d4ac7df-f416-424f-a91b-d247b19adcf8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "silver_query = (cleansed_df.writeStream\n",
    "    .format(\"delta\")\n",
    "    .outputMode(\"append\")\n",
    "    .option(\"checkpointLocation\", \"/FileStore/silver_checkpoint_v1/\")\n",
    "    .start(\"/FileStore/silver_table_v1/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bec4c623-8b9b-4328-9f34-3bce7643e379",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Gold Layer – Aggregate Business Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77a789ad-78ac-4c0d-8046-35172d552dd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#STEP 4: Gold - Aggregate by age\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "gold_df = spark.readStream.format(\"delta\").load(\"/FileStore/silver_table_v1/\")\n",
    "agg_df = gold_df.groupBy(\"age\").agg(count(\"id\").alias(\"employee_count\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2299d615-b2f1-4e52-ab0b-ff0c3ce84895",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gold_query = (agg_df.writeStream\n",
    "    .format(\"delta\")\n",
    "    .outputMode(\"complete\")  # needed for aggregation\n",
    "    .option(\"checkpointLocation\", \"/FileStore/gold_checkpoint_v1/\")\n",
    "    .start(\"/FileStore/gold_table_v1/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "533c3657-5dd3-48d7-a080-a20c59d2497d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    " View Each Layer Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee40bbd9-a44c-4dc4-8748-4d6223c67004",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----+\n|  id|      name| age|\n+----+----------+----+\n|null|FIRST_NAME|null|\n| 198|    Donald|null|\n| 199|   Douglas|null|\n| 200|  Jennifer|null|\n| 201|   Michael|null|\n| 202|       Pat|null|\n| 203|     Susan|null|\n| 204|   Hermann|null|\n| 205|   Shelley|null|\n| 206|   William|null|\n| 100|    Steven|null|\n| 101|     Neena|null|\n| 102|       Lex|null|\n| 103| Alexander|null|\n| 104|     Bruce|null|\n| 105|     David|null|\n| 106|     Valli|null|\n| 107|     Diana|null|\n| 108|     Nancy|null|\n| 109|    Daniel|null|\n+----+----------+----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Bronze\n",
    "spark.read.format(\"delta\").load(\"/FileStore/bronze_table_v1/\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d144e09-0752-43d0-b7bc-5a9d38a7558c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+\n| id|name|age|\n+---+----+---+\n|  1|Aman| 22|\n|  2|Neha| 27|\n|  3|Ravi| 33|\n+---+----+---+\n\n"
     ]
    }
   ],
   "source": [
    "# Silver\n",
    "spark.read.format(\"delta\").load(\"/FileStore/silver_table_v1/\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9075b3e7-7fec-4bde-9ab1-9de172ab2a4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+\n|age|employee_count|\n+---+--------------+\n| 27|             1|\n| 22|             1|\n| 33|             1|\n+---+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Gold\n",
    "spark.read.format(\"delta\").load(\"/FileStore/gold_table_v1/\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4a72603-e37b-4767-942d-ac3fe259d286",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Auto Loader and Medallion Architecture",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}