{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdBmEOVTT88u91sYBWMdP/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikitaj832/Training/blob/main/DataFrame_Operations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Create a DataFrame and filter rows based on conditions.**"
      ],
      "metadata": {
        "id": "G8-CNKz_3EWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create Spark session\n",
        "spark = SparkSession.builder.appName(\"FilterExample\").getOrCreate()\n",
        "\n",
        "# Sample data\n",
        "data = [(\"Niku\", 25), (\"Anchal\", 30), (\"ritu\", 22), (\"geeta\", 35)]\n",
        "columns = [\"Name\", \"Age\"]\n",
        "\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(data, schema=columns)\n",
        "\n",
        "# Show original DataFrame\n",
        "print(\"Original DataFrame:\")\n",
        "df.show()\n",
        "\n",
        "# Filter rows where Age > 25\n",
        "filtered_df = df.filter(df.Age > 25)\n",
        "\n",
        "# Show filtered DataFrame\n",
        "print(\"Filtered DataFrame (Age > 25):\")\n",
        "filtered_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsefmdY755HX",
        "outputId": "69ce08c3-b616-4c04-d6df-dd2e3ebdedf5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "+------+---+\n",
            "|  Name|Age|\n",
            "+------+---+\n",
            "|  Niku| 25|\n",
            "|Anchal| 30|\n",
            "|  ritu| 22|\n",
            "| geeta| 35|\n",
            "+------+---+\n",
            "\n",
            "Filtered DataFrame (Age > 25):\n",
            "+------+---+\n",
            "|  Name|Age|\n",
            "+------+---+\n",
            "|Anchal| 30|\n",
            "| geeta| 35|\n",
            "+------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Show the DataFrame content, collect data into a list, count rows.**"
      ],
      "metadata": {
        "id": "RwLK3pIn6nVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create Spark session\n",
        "spark = SparkSession.builder.appName(\"StudentData\").getOrCreate()\n",
        "\n",
        "# Sample student data\n",
        "students = [\n",
        "    (\"Nikita\", \"IT\", 8.2),\n",
        "    (\"Rahul\", \"CSE\", 7.5),\n",
        "    (\"Anjali\", \"ECE\", 8.9),\n",
        "    (\"Ravi\", \"ME\", 6.8)\n",
        "]\n",
        "\n",
        "columns = [\"Name\", \"Department\", \"CGPA\"]\n",
        "\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(students, columns)\n",
        "\n",
        "# 1. Show the DataFrame content\n",
        "print(\"DataFrame content:\")\n",
        "df.show()\n",
        "\n",
        "# 2. Collect data into a Python list\n",
        "data_list = df.collect()\n",
        "print(\"\\nCollected Data:\")\n",
        "for row in data_list:\n",
        "    print(row.asDict())\n",
        "\n",
        "# 3. Count number of rows\n",
        "total_rows = df.count()\n",
        "print(f\"\\nTotal number of rows: {total_rows}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIS5lW8X6Mc-",
        "outputId": "736ea5dc-883a-4ca1-c1f5-ba1092ecd4b6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame content:\n",
            "+------+----------+----+\n",
            "|  Name|Department|CGPA|\n",
            "+------+----------+----+\n",
            "|Nikita|        IT| 8.2|\n",
            "| Rahul|       CSE| 7.5|\n",
            "|Anjali|       ECE| 8.9|\n",
            "|  Ravi|        ME| 6.8|\n",
            "+------+----------+----+\n",
            "\n",
            "\n",
            "Collected Data:\n",
            "{'Name': 'Nikita', 'Department': 'IT', 'CGPA': 8.2}\n",
            "{'Name': 'Rahul', 'Department': 'CSE', 'CGPA': 7.5}\n",
            "{'Name': 'Anjali', 'Department': 'ECE', 'CGPA': 8.9}\n",
            "{'Name': 'Ravi', 'Department': 'ME', 'CGPA': 6.8}\n",
            "\n",
            "Total number of rows: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Add a new column with withColumn and drop an existing column.**"
      ],
      "metadata": {
        "id": "pptYWavg8fbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Create Spark session\n",
        "spark = SparkSession.builder.appName(\"ModifyColumns\").getOrCreate()\n",
        "\n",
        "# Sample data\n",
        "data = [\n",
        "    (\"Nikita\", 80),\n",
        "    (\"Rahul\", 60),\n",
        "    (\"Anjali\", 90),\n",
        "    (\"Ravi\", 45)\n",
        "]\n",
        "columns = [\"Name\", \"Marks\"]\n",
        "\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# 1. Add a new column 'Result' based on condition\n",
        "df_with_result = df.withColumn(\"Result\", col(\"Marks\") >= 60)\n",
        "\n",
        "# 2. Drop the 'Marks' column\n",
        "df_final = df_with_result.drop(\"Marks\")\n",
        "\n",
        "# Show final DataFrame\n",
        "df_final.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WybkP2zy7sRf",
        "outputId": "3022df29-76c6-459e-9f90-9564f1bc5b64"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+\n",
            "|  Name|Result|\n",
            "+------+------+\n",
            "|Nikita|  true|\n",
            "| Rahul|  true|\n",
            "|Anjali|  true|\n",
            "|  Ravi| false|\n",
            "+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CvFa2-6V_fno"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}